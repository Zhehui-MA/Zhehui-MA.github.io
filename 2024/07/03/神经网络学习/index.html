<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>神经网络学习 | Hexo</title>
  <link rel="stylesheet" href="/css/fonts/Chinese-normal-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/ChineseMono-normal-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/Chinese-italic-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/Chinese-normal-bold.min.css">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="description" content="1.BP1.1 bilibili泊松方程代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686">
  
  
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox-1.3.4.css">
  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div id="nav-outer">
  <nav id="main-nav" class="outer">
    <a id="main-nav-toggle" class="nav-icon"></a>
    
      <a class="main-nav-link" href="/">Home</a>
    
      <a class="main-nav-link" href="/archives">Archives</a>
    
      <a class="main-nav-link" href="/about">About</a>
    
    <div class="main-nav-space-between"></div>
    
  </nav>
</div>
<div id="header-title">
  <h1 id="logo-wrap">
    <a href="/" id="logo">Hexo</a>
  </h1>
  
</div>

      <div id="content" class="outer">
        <section id="main"><article id="post-神经网络学习" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/07/03/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/" class="article-date">
  <time class="dt-published" datetime="2024-07-03T06:57:35.000Z" itemprop="datePublished">2024-07-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      神经网络学习
    </h1>
  

      </header>
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="1-BP"><a href="#1-BP" class="headerlink" title="1.BP"></a>1.BP</h1><h2 id="1-1-bilibili泊松方程代码"><a href="#1-1-bilibili泊松方程代码" class="headerlink" title="1.1 bilibili泊松方程代码"></a>1.1 bilibili泊松方程代码</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line">ub=1;</span><br><span class="line">lb=-1;%上下边界</span><br><span class="line"></span><br><span class="line">%均匀生成输入数据点<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>生成sobolset序列[0,1]随机点</span><br><span class="line">pointSet = sobolset(2);     %2维空间</span><br><span class="line">numBP = 500;                  %每个边界上有500个数据点</span><br><span class="line">boundaryPoints = net(pointSet,numBP*2);%生成0~1之间的2维随机点</span><br><span class="line">boundaryPointsMap = (boundaryPoints-0)./(1-0).*(ub-lb)+lb;%将随机点映射到定义域内</span><br><span class="line"></span><br><span class="line">%边界点</span><br><span class="line">xb1 = lb.*ones(numBP,1);</span><br><span class="line">xb2 = ub.*ones(numBP,1);</span><br><span class="line">yb1 = lb.*ones(numBP,1);</span><br><span class="line">yb2 = ub.*ones(numBP,1);</span><br><span class="line"></span><br><span class="line">%其它点</span><br><span class="line">x1 = boundaryPointsMap(1:numBP,1);</span><br><span class="line">y1 = boundaryPointsMap(1:numBP,2);</span><br><span class="line">x2 = boundaryPointsMap(numBP+1:end,1);</span><br><span class="line">y2 = boundaryPointsMap(numBP+1:end,1);</span><br><span class="line"></span><br><span class="line">%将边界数据组织成矩阵</span><br><span class="line">xyb = [xb1,y1 ; xb2,y2 ; x1,yb1 ; x2,yb2];</span><br><span class="line">xyb = xyb&#x27;;%所有边界点坐标的集合</span><br><span class="line"></span><br><span class="line">%在非边界范围生成50000个数据点</span><br><span class="line">numInternalPoints = 10000;</span><br><span class="line">internalPoints1 = numBP*2+1;%避免与之前取到重复的点</span><br><span class="line">internalPoints2 = numBP*2+numInternalPoints;</span><br><span class="line"></span><br><span class="line">points = net(pointSet,internalPoints2);</span><br><span class="line">points = points(internalPoints1:internalPoints2,:);</span><br><span class="line"></span><br><span class="line">%将生成的数据点映射到定义域内</span><br><span class="line">pointsMap = ((points-0)./(1-0)).*(ub-lb)+lb;</span><br><span class="line">x = pointsMap(:,1);</span><br><span class="line">y = pointsMap(:,2);</span><br><span class="line"></span><br><span class="line">ds = arrayDatastore([x y]);%基于数组[x y]建立数据存储arrds,也就是根据xy坐标生成一个可用于神经网络的数据类型</span><br><span class="line">%% 构建神经网络</span><br><span class="line">numLayers = 9;</span><br><span class="line">numNeurons = 64;</span><br><span class="line"></span><br><span class="line">layers = featureInputLayer(2);%输入层有x和y两个变量</span><br><span class="line">for i = 1:numLayers-1%因为已经有输入层了<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>所以-1</span><br><span class="line">    layers = [</span><br><span class="line">        layers</span><br><span class="line">        fullyConnectedLayer(numNeurons,&quot;BiasInitializer&quot;,&quot;narrow-normal&quot;,&#x27;WeightsInitializer&#x27;,&#x27;glorot&#x27;)%全连接层</span><br><span class="line">        tanhLayer];%激活函数</span><br><span class="line">end</span><br><span class="line">layers = [</span><br><span class="line">    layers</span><br><span class="line">    fullyConnectedLayer(1)];%输出一个全连接层</span><br><span class="line"></span><br><span class="line">nnNet = dlnetwork(layers);</span><br><span class="line">nnNet = dlupdate(@double,nnNet);%将网络参数设置成double类型</span><br><span class="line"></span><br><span class="line">%设置训练参数</span><br><span class="line">numEpochs = 1000;%循环轮数</span><br><span class="line">miniBatchSize = 64;%更新参数的个数</span><br><span class="line">executionEnvironment = &quot;gpu&quot;;</span><br><span class="line">initialLearnRate = 0.01;%初始学习率</span><br><span class="line">decayRate = 0.005;%学习率的衰减率</span><br><span class="line"></span><br><span class="line">%训练数据集</span><br><span class="line">%构建minibatch队列</span><br><span class="line">mbq = minibatchqueue(ds,...</span><br><span class="line">    MiniBatchFormat=&quot;BC&quot;,...</span><br><span class="line">    OutputCast=&quot;double&quot;,...</span><br><span class="line">    OutputEnvironment=executionEnvironment);</span><br><span class="line">%边界点</span><br><span class="line">dlxyb = dlarray(xyb,&quot;CB&quot;);%<span class="bd-box"><h-char class="bd bd-end"><h-inner>（</h-inner></h-char></span>channel,batch)</span><br><span class="line">if (executionEnvironment ==&quot;auto&quot;&amp;&amp; canUseGPU || executionEnvironment==&quot;gpu&quot;)</span><br><span class="line">    dlxyb = gpuArray(dlxyb);%将数据类型转换成可在gpu上执行的类型</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">%% 训练过程图形化显示</span><br><span class="line">averageGrad = [];</span><br><span class="line">averageSqGrad = [];</span><br><span class="line">maxIteration = ceil(numInternalPoints/miniBatchSize).*numEpochs;</span><br><span class="line">monitor = trainingProgressMonitor;</span><br><span class="line">monitor.Info = [&quot;LearningRate&quot;,&quot;Epoch&quot;,&quot;Iteration&quot;,&quot;ExecutionEnvironment&quot;,&quot;LossF&quot;,&quot;LossB&quot;,&quot;A&quot;]</span><br><span class="line">monitor.Metrics = [&quot;LossF&quot;,&quot;LossB&quot;];</span><br><span class="line">monitor.XLabel = &quot;Interation&quot;;</span><br><span class="line">groupSubPlot(monitor,&quot;LossF&quot;,&quot;LossF&quot;);</span><br><span class="line">groupSubPlot(monitor,&quot;LossB&quot;,&quot;LossB&quot;);</span><br><span class="line"></span><br><span class="line">%% 自定义训练过程</span><br><span class="line">iteration = 0;</span><br><span class="line">for epoch = 1:numEpochs</span><br><span class="line">    shuffle(mbq);%对mbq中的数据进行乱序处理</span><br><span class="line">    while hasdata(mbq)</span><br><span class="line">        iteration = iteration+1;</span><br><span class="line">        xy = next(mbq);</span><br><span class="line">        x = xy(1,:);</span><br><span class="line">        y = xy(2,:);</span><br><span class="line"></span><br><span class="line">​        %损失函数对神经网络的参数求梯度</span><br><span class="line">​        [lossF,lossB,gradients] = dlfeval(@modelLoss,nnNet,x,y,dlxyb);%损失函数的构建是物理信息神经网络的核心</span><br><span class="line">​        %更新学习率</span><br><span class="line">​        learningRate = initialLearnRate./(1+decayRate.*iteration);%就是随着迭代次数的一个衰减<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>没什么好说的</span><br><span class="line">​        %更新神经网络参数</span><br><span class="line">​        [nnNet,averageGrad,averageSqGrad] = adamupdate(nnNet,gradients,averageGrad,...%梯度下降方法<span class="bd-box"><h-char class="bd bd-beg"><h-inner>？</h-inner></h-char></span>主要是更新了一个学习率</span><br><span class="line">​            averageSqGrad,iteration,learningRate);</span><br><span class="line">​        updateInfo(monitor,...%图形化的一些信息</span><br><span class="line">​            LearningRate = learningRate,...</span><br><span class="line">​            Epoch = &quot;第&quot;+string(epoch)+&quot;轮<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>共&quot;+string(numEpochs+&quot;轮&quot;),...</span><br><span class="line">​            ExecutionEnvironment = executionEnvironment,...</span><br><span class="line">​            LossF = lossF,...</span><br><span class="line">​            LossB = lossB,...</span><br><span class="line">​            Iteration = &quot;第&quot;+string(iteration)+&quot;次迭代<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>共&quot;+string(maxIteration)+&quot;次&quot;);</span><br><span class="line">​    </span><br><span class="line">​        recordMetrics(monitor,iteration,...</span><br><span class="line">​            LossF = lossF,...</span><br><span class="line">​            LossB = lossB);</span><br><span class="line">​        monitor.Progress = 100 * iteration/maxIteration;</span><br><span class="line">​    end</span><br><span class="line"></span><br><span class="line">end</span><br><span class="line">%% 输出函数A的结果</span><br><span class="line">numInternalPoints = 200000;</span><br><span class="line">testPoints = net(pointSet,numInternalPoints);</span><br><span class="line"></span><br><span class="line">%映射</span><br><span class="line">testPointsMap = ((testPoints-0)./(1-0)).*(ub-lb)+lb;</span><br><span class="line">testX = testPointsMap(:,1)&#x27;;</span><br><span class="line">testY = testPointsMap(:,2)&#x27;;</span><br><span class="line"></span><br><span class="line">%边界点</span><br><span class="line">oneNum = numInternalPoints.*0.2;%边界点个数</span><br><span class="line">oneTest = dlarray(ones(1,oneNum));</span><br><span class="line">negativeOneTest = dlarray(-1.*oneTest);</span><br><span class="line">xIdx = randi(numInternalPoints,[1,oneNum]);</span><br><span class="line">yIdx = randi(numInternalPoints,[1,oneNum]);</span><br><span class="line"></span><br><span class="line">testX(xIdx) = 1;</span><br><span class="line">testY(yIdx) = -1;</span><br><span class="line"></span><br><span class="line">dlx = dlarray(testX,&quot;CB&quot;);</span><br><span class="line">dlY = dlarray(testY,&quot;CB&quot;);</span><br><span class="line">aPred = functionPre(nnNet,dlx,dlY);</span><br><span class="line">aPredArray = extractdata(gather(aPred));</span><br><span class="line"></span><br><span class="line">x0 = 0;</span><br><span class="line">y0 = 0;</span><br><span class="line">r = 0.2;</span><br><span class="line">%%</span><br><span class="line">figure</span><br><span class="line">scatter(testX,testY,5,aPredArray,&quot;filled&quot;);</span><br><span class="line">% x_plot = linspace(-1,1,400);</span><br><span class="line">% y_plot = x_plot;</span><br><span class="line">% [X Y A] = griddata(testX,testY,aPredArray,x_plot&#x27;,y_plot,&#x27;nearest&#x27;);</span><br><span class="line">% surf(X,Y,A);</span><br><span class="line">% shading interp; </span><br><span class="line">colormap parula</span><br><span class="line">colorbar</span><br><span class="line">hold on</span><br><span class="line">plotCircle(x0,y0,0.2);</span><br><span class="line">hold off;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/07/03/openfoam%E5%AD%A6%E4%B9%A0/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          openfoam学习
        
      </div>
    </a>
  
  
    <a href="/2024/07/02/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">
        
          Hello
        
      </div>
    </a>
  
</nav>

  
</article>


</section>
        
      </div>
      <footer id="footer">
  
    <aside id="sidebar" class="outer">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/07/03/openfoam%E5%AD%A6%E4%B9%A0/">openfoam学习</a>
          </li>
        
          <li>
            <a href="/2024/07/03/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/">神经网络学习</a>
          </li>
        
          <li>
            <a href="/2024/07/02/hello-world/">Hello</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    

  
    
  
</aside>
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
        <p></p> 
      
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="/js/clipboard.min.js"></script>
<script src="/js/jquery-1.4.3.min.js"></script>

<script src="/fancybox/jquery.fancybox-1.3.4.pack.js"></script>


<script src="/js/script.js"></script>






<script>
  MathJax = {
    options: {
      enableMenu: false
    },
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
    }
  };
</script>
<!-- <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    CommonHTML: {
      linebreaks: false
    }
  });
  </script> -->
<script type="text/javascript" id="MathJax-script" async
  src="/mathjax/tex-chtml.js">
</script>
<!-- <script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_CHTML">
</script> -->

  </div>
</body>
</html>